{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7bb4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\ocr_engine\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\admin\\anaconda3\\envs\\ocr_engine\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder, CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7fa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "train_transform=T.Compose([#T.Resize(32),\n",
    "                           T.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "                           T.RandomHorizontalFlip(),\n",
    "                           T.ToTensor(),T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "valid_transform=T.Compose([T.ToTensor(),T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "train_ds=CIFAR100(root=\"data\",train=True,transform=train_transform,download=False)\n",
    "valid_ds=CIFAR100(root=\"data\",train=False,transform=valid_transform,download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ec3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec93acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e7aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam,index\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "\n",
    "def mix_freq(img,label,b_kernel,e_kernel,lamB=0.5,lamE=0.5):\n",
    "    with torch.no_grad():\n",
    "        blured_img=b_kernel(img)\n",
    "        edged_img=e_kernel(img)[1].expand(-1,3,-1,-1)\n",
    "        idx = torch.randperm(blured_img.shape[0])\n",
    "        edged_img=edged_img[idx]\n",
    "        y_b,y_e=label,label[idx]\n",
    "        mixed_img=lamB*blured_img+lamE*edged_img#+0.2*img\n",
    "    return mixed_img,y_b,y_e,lamB,lamE,idx\n",
    "    \n",
    "def mix_freq_classic(img,label,b_kernel,alpha=1):\n",
    "    lam=np.random.beta(alpha,alpha)\n",
    "    with torch.no_grad():\n",
    "        edged_img=img-b_kernel(img)\n",
    "    idx = torch.randperm(img.shape[0])\n",
    "    edged_img=edged_img[idx]\n",
    "    y_a,y_e=label,label[idx]\n",
    "    mixed_img=lam*img+(1-lam)*edged_img\n",
    "    ##+0.2*img\n",
    "    return mixed_img,y_a,y_e,lam\n",
    "\n",
    "    return mixed_img,y_b,y_e\n",
    "def mixfreq_criterion(criterion, pred, y_a, y_b):\n",
    "    return  criterion(pred, y_a) + criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9c75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803f962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import conv3x3, _resnet\n",
    "\n",
    "class PreactBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(PreactBasicBlock, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc24116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _resnet('resnet18', PreactBasicBlock, [2, 2, 2, 2], False, False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8d07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        images=images.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    def training_step_mixup(self, batch,epoch,criterion):\n",
    "        images, labels = batch \n",
    "        images=images.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "        if epoch<550:\n",
    "            mixed_x, y_a, y_b, lam,index=mixup_data(images,labels)\n",
    "            out = self(mixed_x)                  # Generate predictions\n",
    "            loss = mixup_criterion(criterion,out,y_a,y_b,lam)\n",
    "        else:\n",
    "            out = self(images)                  # Generate predictions\n",
    "            loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    def training_step_mixfreq(self, batch,epoch,criterion,b_kernel,e_kernel):\n",
    "        images, labels = batch \n",
    "        images=images.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "        if epoch<250:\n",
    "            mixed_x, y_a, y_b, lam,index=mix_freq(images,b_kernel,e_kernel,labels)\n",
    "            mixed_x=mixed_x.to(self.device)\n",
    "            out = self(mixed_x)                  # Generate predictions\n",
    "            loss = mixup_criterion(criterion,out,y_a,y_b)\n",
    "        else:\n",
    "            out = self(images)                  # Generate predictions\n",
    "            loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        images, labels = batch \n",
    "        images=images.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    " #       print(labels)\n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"Train Loss\": result['train_loss'],\n",
    "        \"Val Accuracy\": result['val_acc'],\n",
    "        \"Val Loss\": result['val_loss'],\n",
    "        \"Learning Rate\": result['lrs'][-1]},\n",
    "            )\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb671ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(ImageClassificationBase):\n",
    "    def __init__(self,backbone,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone=backbone\n",
    "        self.device=device\n",
    "    def forward(self, xb):\n",
    "        out = self.backbone(xb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfa9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e16b2fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDODEL DEVICE\n"
     ]
    }
   ],
   "source": [
    "model=Base_Model(model,device='cuda')\n",
    "model.to('cuda')\n",
    "print(\"MDODEL DEVICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6af39482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CannyFilter(\n",
       "  (gaussian_filter): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (sobel_filter_x): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (sobel_filter_y): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (directional_filter): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (hysteresis): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kernel import CannyFilter,get_thin_kernels,get_gaussian_kernel\n",
    "blur_kernel=CannyFilter(k_gaussian=3,k_sobel=3,blur=True).eval()\n",
    "blur_kernel.to('cuda')\n",
    "edge_kernel=CannyFilter(k_gaussian=1,k_sobel=3,blur=False).eval()\n",
    "edge_kernel.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586e77c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CannyFilter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19884/1295387.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mblur_kernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCannyFilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_gaussian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk_sobel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0medge_kernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCannyFilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_gaussian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk_sobel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmixed_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmix_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblur_kernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medge_kernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CannyFilter' is not defined"
     ]
    }
   ],
   "source": [
    "img,label=next(iter(train_dl))\n",
    "img=img.to(\"cuda\")\n",
    "blur_kernel=CannyFilter(k_gaussian=3,k_sobel=3,blur=True)\n",
    "edge_kernel=CannyFilter(k_gaussian=1,k_sobel=3,blur=False)\n",
    "mixed_img,_,_,_,_,idx=mix_freq(img,label,blur_kernel,edge_kernel,lamB=0.5,lamE=0.5)\n",
    "grid_img = torchvision.utils.make_grid(torch.cat([mixed_img[0:4],img[0:4],img[idx[0:4]]]).detach(), nrow=4,normalize=True)\n",
    "#gt=[label_name[x.long()] for x in LABELS]\n",
    "plt.figure(figsize=(12,8))\n",
    "#plt.title(gt)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812888ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff93fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bff162aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step_mixfreq(batch,epoch,nn.CrossEntropyLoss(),blur_kernel,edge_kernel)\n",
    "            return batch\n",
    "            #loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5f30c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 4.838977336883545, 'val_acc': 0.009512867778539658}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, valid_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885b04c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhslrock\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hslrock/Augmentation_Strategy_CIFAR100/runs/1v68iwux\" target=\"_blank\">faithful-wave-17</a></strong> to <a href=\"https://wandb.ai/hslrock/Augmentation_Strategy_CIFAR100\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 300\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 0.5e-4\n",
    "opt_func = torch.optim.Adam\n",
    "wandb.init(project=\"Augmentation_Strategy_CIFAR100\")\n",
    "wandb.run.name = \"MixFreq_PreAct_ResNet18_0.01_300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02801cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1314,  0.0056, -0.0972,  ...,  1.4098,  1.2557,  1.0844],\n",
      "          [ 0.0227,  0.0398,  0.1083,  ...,  1.4269,  1.3070,  1.1529],\n",
      "          [ 0.0912,  0.2453,  0.2796,  ...,  1.5639,  1.4783,  1.2728],\n",
      "          ...,\n",
      "          [ 0.8789,  1.1529,  0.3823,  ...,  0.8789,  0.7933,  0.5022],\n",
      "          [ 0.1939,  0.2624, -0.1828,  ...,  1.5639,  1.4612,  1.2214],\n",
      "          [ 0.5536,  0.6392,  0.6392,  ...,  1.8722,  1.8208,  1.8037]],\n",
      "\n",
      "         [[-0.0399,  0.1001,  0.0126,  ...,  1.2206,  1.0980,  0.9230],\n",
      "          [ 0.0826,  0.1001,  0.1877,  ...,  1.1155,  1.0105,  0.9405],\n",
      "          [ 0.1001,  0.3102,  0.3452,  ...,  1.2381,  1.1331,  1.0280],\n",
      "          ...,\n",
      "          [ 0.5903,  0.8354,  0.1702,  ...,  0.4503,  0.3803,  0.2227],\n",
      "          [ 0.0126,  0.0651, -0.3025,  ...,  1.0105,  0.9580,  0.8179],\n",
      "          [ 0.3803,  0.4678,  0.4853,  ...,  1.2031,  1.2031,  1.2381]],\n",
      "\n",
      "         [[-0.7064, -0.5321, -0.7238,  ..., -0.0964, -0.2010, -0.4101],\n",
      "          [-0.6890, -0.6367, -0.6367,  ..., -0.1835, -0.3055, -0.4275],\n",
      "          [-0.7413, -0.5321, -0.6018,  ..., -0.1312, -0.2532, -0.4275],\n",
      "          ...,\n",
      "          [-0.5147, -0.1661, -0.4624,  ..., -0.6890, -0.6715, -0.8807],\n",
      "          [-0.8981, -0.7761, -0.9330,  ..., -0.3578, -0.3578, -0.5321],\n",
      "          [-0.5321, -0.4275, -0.3404,  ..., -0.3753, -0.3753, -0.3055]]],\n",
      "\n",
      "\n",
      "        [[[-1.3130, -1.4329, -1.2959,  ...,  2.0948,  2.0777,  2.0948],\n",
      "          [-1.3473, -1.4158, -1.3644,  ...,  2.1804,  2.1633,  2.1462],\n",
      "          [-1.2788, -1.3302, -1.4672,  ...,  2.0777,  2.1290,  2.1290],\n",
      "          ...,\n",
      "          [ 0.6734,  0.3309,  0.4508,  ...,  0.1768,  0.5193,  0.6049],\n",
      "          [ 0.5878,  0.4166,  0.4508,  ...,  0.2796, -0.2342,  0.0569],\n",
      "          [ 0.6734,  0.5193,  0.4508,  ...,  0.1939, -0.5082, -0.4054]],\n",
      "\n",
      "         [[-1.1604, -1.2654, -1.0728,  ...,  2.2710,  2.2535,  2.2710],\n",
      "          [-1.2654, -1.2304, -1.1604,  ...,  2.3585,  2.3410,  2.3235],\n",
      "          [-1.2129, -1.1253, -1.3004,  ...,  2.2535,  2.3060,  2.3060],\n",
      "          ...,\n",
      "          [ 0.6779,  0.3803,  0.5028,  ...,  0.1527,  0.4678,  0.4678],\n",
      "          [ 0.5203,  0.4153,  0.4678,  ...,  0.2577, -0.2150, -0.0224],\n",
      "          [ 0.6604,  0.4853,  0.4328,  ...,  0.1702, -0.4951, -0.3725]],\n",
      "\n",
      "         [[-0.8981, -1.0898, -1.0724,  ...,  2.4831,  2.4657,  2.4831],\n",
      "          [-1.1247, -1.0724, -1.0724,  ...,  2.5703,  2.5529,  2.5354],\n",
      "          [-1.0898, -1.0201, -1.1421,  ...,  2.4657,  2.5180,  2.5180],\n",
      "          ...,\n",
      "          [ 0.8971,  0.6182,  0.8274,  ...,  0.4439,  0.6879,  0.7751],\n",
      "          [ 0.7054,  0.6008,  0.7402,  ...,  0.4962, -0.0092,  0.2696],\n",
      "          [ 0.8448,  0.7576,  0.6182,  ...,  0.4439, -0.1835, -0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8618,  1.0159,  1.1358,  ...,  0.7591, -0.6281, -0.6794],\n",
      "          [ 0.9303,  1.1015,  1.0844,  ...,  1.0502, -0.1657, -0.3027],\n",
      "          [ 0.9474,  1.0331,  0.7762,  ...,  0.9988,  0.3823,  0.0741],\n",
      "          ...,\n",
      "          [ 1.1358,  1.1529,  1.0331,  ..., -0.3369, -0.7479, -0.9705],\n",
      "          [ 1.0844,  1.1187,  1.1872,  ...,  0.7419,  0.1083, -0.6281],\n",
      "          [ 1.1700,  1.2385,  1.2899,  ...,  1.2899,  1.0844,  0.6221]],\n",
      "\n",
      "         [[ 0.9055,  1.0630,  1.2381,  ...,  0.9580, -0.1625, -0.0924],\n",
      "          [ 1.0455,  1.2381,  1.2206,  ...,  1.2731,  0.2927,  0.2577],\n",
      "          [ 1.1681,  1.2556,  0.9055,  ...,  1.2206,  0.8004,  0.5553],\n",
      "          ...,\n",
      "          [ 1.2206,  1.1856,  1.0280,  ..., -0.1975, -0.5651, -0.7052],\n",
      "          [ 1.1506,  1.1331,  1.1856,  ...,  0.9055,  0.3102, -0.3550],\n",
      "          [ 1.2381,  1.2731,  1.2906,  ...,  1.4482,  1.2556,  0.8354]],\n",
      "\n",
      "         [[-1.0550, -0.9678, -0.9678,  ..., -0.3927, -0.8458, -0.5670],\n",
      "          [-0.8981, -0.7587, -0.8110,  ..., -0.0441, -0.5321, -0.3578],\n",
      "          [-0.7238, -0.6193, -0.8458,  ..., -0.0092, -0.2532, -0.2707],\n",
      "          ...,\n",
      "          [-0.7587, -0.7936, -0.8458,  ..., -1.1944, -1.3861, -1.3339],\n",
      "          [-0.8807, -0.8981, -0.8110,  ..., -0.4275, -0.7238, -1.0376],\n",
      "          [-0.8633, -0.7936, -0.7413,  ..., -0.0615, -0.0441, -0.2532]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0048, -1.0048, -0.9877,  ..., -0.9705, -0.9705, -0.9877],\n",
      "          [-0.9705, -0.9877, -0.9705,  ..., -0.9534, -0.9705, -0.9705],\n",
      "          [-0.9534, -0.9705, -0.9705,  ..., -0.9363, -0.9363, -0.9534],\n",
      "          ...,\n",
      "          [ 0.6906,  0.5022,  0.3309,  ..., -1.3644, -0.8678, -0.6109],\n",
      "          [ 0.5193,  0.4337,  0.4166,  ..., -1.2959, -0.7137, -0.3883],\n",
      "          [ 0.1597,  0.3652,  0.3994,  ..., -0.1999,  0.1083, -0.1828]],\n",
      "\n",
      "         [[ 0.3452,  0.3277,  0.3452,  ...,  0.3803,  0.3803,  0.3978],\n",
      "          [ 0.3627,  0.3452,  0.3627,  ...,  0.3978,  0.3978,  0.4153],\n",
      "          [ 0.3803,  0.3627,  0.3803,  ...,  0.4153,  0.4153,  0.4328],\n",
      "          ...,\n",
      "          [ 0.6779,  0.5028,  0.4153,  ..., -1.2829, -0.7577, -0.5301],\n",
      "          [ 0.5553,  0.4853,  0.5028,  ..., -1.3004, -0.6702, -0.3025],\n",
      "          [ 0.2402,  0.4503,  0.5203,  ..., -0.1625,  0.2227, -0.0749]],\n",
      "\n",
      "         [[ 1.6117,  1.5942,  1.6117,  ...,  1.6814,  1.6814,  1.6814],\n",
      "          [ 1.6465,  1.6117,  1.6291,  ...,  1.6988,  1.6988,  1.6988],\n",
      "          [ 1.6640,  1.6291,  1.6465,  ...,  1.7163,  1.7163,  1.7163],\n",
      "          ...,\n",
      "          [ 0.6531,  0.5136,  0.3568,  ..., -1.0550, -0.5321, -0.3404],\n",
      "          [ 0.5485,  0.4788,  0.4788,  ..., -1.0898, -0.5495, -0.2532],\n",
      "          [ 0.2522,  0.4614,  0.5485,  ..., -0.1312,  0.2696, -0.0092]]],\n",
      "\n",
      "\n",
      "        [[[-1.7069, -1.6727, -1.6384,  ..., -1.7925, -1.7925, -1.8097],\n",
      "          [-1.7069, -1.6727, -1.6213,  ..., -1.8439, -1.7925, -1.8439],\n",
      "          [-1.6898, -1.6727, -1.5357,  ..., -1.8610, -1.8097, -1.8439],\n",
      "          ...,\n",
      "          [-1.9809, -1.9467, -1.9124,  ...,  0.8789,  1.0844,  0.9817],\n",
      "          [-1.8268, -1.6727, -1.6042,  ...,  0.8447,  1.0673,  1.1015],\n",
      "          [-1.6898, -1.5870, -1.4843,  ...,  1.0331,  1.0331,  0.9132]],\n",
      "\n",
      "         [[-1.5455, -1.3880, -1.3880,  ..., -1.6681, -1.6681, -1.6681],\n",
      "          [-1.5455, -1.3880, -1.3704,  ..., -1.7206, -1.6681, -1.7031],\n",
      "          [-1.5280, -1.4055, -1.3004,  ..., -1.7381, -1.6856, -1.7031],\n",
      "          ...,\n",
      "          [-1.8957, -1.8782, -1.8431,  ...,  0.4503,  0.5203,  0.4503],\n",
      "          [-1.7556, -1.6331, -1.5630,  ...,  0.4503,  0.4678,  0.4853],\n",
      "          [-1.6506, -1.5805, -1.4930,  ...,  0.8354,  0.6078,  0.4503]],\n",
      "\n",
      "         [[-1.4907, -1.3861, -1.3687,  ..., -1.4907, -1.5256, -1.5779],\n",
      "          [-1.4559, -1.3513, -1.3339,  ..., -1.5430, -1.5256, -1.5953],\n",
      "          [-1.4384, -1.3861, -1.2467,  ..., -1.5604, -1.5430, -1.5953],\n",
      "          ...,\n",
      "          [-1.6650, -1.6302, -1.6127,  ...,  0.4614,  0.4962,  0.4614],\n",
      "          [-1.5081, -1.3861, -1.3164,  ...,  0.6182,  0.4962,  0.4788],\n",
      "          [-1.4036, -1.3164, -1.2293,  ...,  1.1062,  0.7925,  0.5834]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2318,  2.2318,  2.2147,  ...,  1.7694,  1.6667,  1.6495],\n",
      "          [ 2.2147,  2.2318,  2.2147,  ...,  1.8379,  1.7865,  1.6667],\n",
      "          [ 2.2318,  2.2147,  2.2147,  ...,  1.7009,  1.7523,  1.6495],\n",
      "          ...,\n",
      "          [ 0.2453,  0.3309,  1.6324,  ...,  0.9132,  0.9303,  0.8789],\n",
      "          [-0.0801,  0.0569,  1.5810,  ...,  0.8789,  0.9303,  0.8789],\n",
      "          [ 0.1254,  0.1254,  1.5639,  ...,  0.8618,  0.8961,  0.8447]],\n",
      "\n",
      "         [[ 2.4111,  2.3936,  2.3936,  ...,  1.5182,  1.5007,  1.4482],\n",
      "          [ 2.3761,  2.3936,  2.3936,  ...,  1.3782,  1.5007,  1.4832],\n",
      "          [ 2.3410,  2.3761,  2.3936,  ...,  1.0630,  1.3606,  1.5532],\n",
      "          ...,\n",
      "          [-0.2850,  0.0476,  1.6232,  ...,  0.5203,  0.5378,  0.4853],\n",
      "          [-0.4951, -0.1975,  1.5532,  ...,  0.5203,  0.5553,  0.5028],\n",
      "          [ 0.0476, -0.0224,  1.5182,  ...,  0.5378,  0.5378,  0.4678]],\n",
      "\n",
      "         [[ 2.6400,  2.6226,  2.6051,  ...,  2.0300,  2.0648,  2.0474],\n",
      "          [ 2.6226,  2.6226,  2.6051,  ...,  1.9254,  2.1171,  2.0648],\n",
      "          [ 2.6051,  2.6051,  2.6051,  ...,  1.4897,  1.9080,  2.0648],\n",
      "          ...,\n",
      "          [ 0.7402,  0.7751,  2.0474,  ...,  1.4548,  1.4722,  1.4200],\n",
      "          [ 0.4265,  0.5136,  1.9951,  ...,  1.4374,  1.4897,  1.4374],\n",
      "          [ 0.5659,  0.5834,  1.9777,  ...,  1.4548,  1.4722,  1.4025]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11496/2791459883.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(epochs, max_lr, model, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mlrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step_mixfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblur_kernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medge_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#loss = model.training_step(batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11496/1903881388.py\u001b[0m in \u001b[0;36mtraining_step_mixfreq\u001b[1;34m(self, batch, epoch, criterion, b_kernel, e_kernel)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mmixed_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmix_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_kernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me_kernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mmixed_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmixed_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixed_x\u001b[0m\u001b[1;33m)\u001b[0m                  \u001b[1;31m# Generate predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11496/3525245160.py\u001b[0m in \u001b[0;36mmix_freq\u001b[1;34m(img, label, b_kernel, e_kernel, lamB, lamE, use_cuda)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mblured_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m        \u001b[1;31m# edged_img=img-blured_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0medged_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ocr_engine\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\2021-AI-Highly-Cluttered-Dataset\\metric_hyun\\kernel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img, low_threshold, high_threshold, hysteresis)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mblurred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mgrad_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msobel_filter_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblurred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[0mgrad_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msobel_filter_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblurred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ocr_engine\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ocr_engine\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ocr_engine\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2754a",
   "metadata": {},
   "source": [
    "## VANILA RESNET18 (NO AUG)\n",
    "\n",
    "Epoch [94], last_lr: 0.00013, train_loss: 0.3673, val_loss: 1.6711, val_acc: 0.6126  \n",
    "Epoch [95], last_lr: 0.00008, train_loss: 0.3603, val_loss: 1.6710, val_acc: 0.6131  \n",
    "Epoch [96], last_lr: 0.00005, train_loss: 0.3479, val_loss: 1.6732, val_acc: 0.6127  \n",
    "Epoch [97], last_lr: 0.00002, train_loss: 0.3484, val_loss: 1.6774, val_acc: 0.6133  \n",
    "Epoch [98], last_lr: 0.00001, train_loss: 0.3424, val_loss: 1.6757, val_acc: 0.6131  \n",
    "Epoch [99], last_lr: 0.00000, train_loss: 0.3499, val_loss: 1.6706, val_acc: 0.6132  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fcfb7",
   "metadata": {},
   "source": [
    "## VANILLA RESNET18 (MIXUP)\n",
    "Epoch [595], last_lr: 0.00000, train_loss: 0.7558, val_loss: 1.3887, val_acc: 0.6273   \n",
    "Epoch [596], last_lr: 0.00000, train_loss: 0.7481, val_loss: 1.3862, val_acc: 0.6294  \n",
    "Epoch [597], last_lr: 0.00000, train_loss: 0.7560, val_loss: 1.3890, val_acc: 0.6275  \n",
    "Epoch [598], last_lr: 0.00000, train_loss: 0.7582, val_loss: 1.3909, val_acc: 0.6296  \n",
    "Epoch [599], last_lr: 0.00000, train_loss: 0.7508, val_loss: 1.3876, val_acc: 0.6293  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452adcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2516b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a31ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
