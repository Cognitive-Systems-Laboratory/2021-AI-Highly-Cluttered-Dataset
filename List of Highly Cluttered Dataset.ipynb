{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ed9b70",
   "metadata": {},
   "source": [
    "# List of Highly Cluttered Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244f4e0",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#General\" data-toc-modified-id=\"General-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>General</a></span><ul class=\"toc-item\"><li><span><a href=\"#Everingham,-Mark,-et-al.-&quot;The-pascal-visual-object-classes-(voc)-challenge.&quot;-International-journal-of-computer-vision-88.2-(2010):-303-338.\" data-toc-modified-id=\"Everingham,-Mark,-et-al.-&quot;The-pascal-visual-object-classes-(voc)-challenge.&quot;-International-journal-of-computer-vision-88.2-(2010):-303-338.-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Everingham, Mark, et al. \"The pascal visual object classes (voc) challenge.\" International journal of computer vision 88.2 (2010): 303-338.</a></span></li><li><span><a href=\"#Lin,-Tsung-Yi,-et-al.-&quot;Microsoft-coco:-Common-objects-in-context.&quot;-European-conference-on-computer-vision.-Springer,-Cham,-2014.\" data-toc-modified-id=\"Lin,-Tsung-Yi,-et-al.-&quot;Microsoft-coco:-Common-objects-in-context.&quot;-European-conference-on-computer-vision.-Springer,-Cham,-2014.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Lin, Tsung-Yi, et al. \"Microsoft coco: Common objects in context.\" European conference on computer vision. Springer, Cham, 2014.</a></span></li><li><span><a href=\"#Gupta,-Agrim,-Piotr-Dollar,-and-Ross-Girshick.-&quot;LVIS:-A-dataset-for-large-vocabulary-instance-segmentation.&quot;-Proceedings-of-the-IEEE/CVF-Conference-on-Computer-Vision-and-Pattern-Recognition.-2019.\" data-toc-modified-id=\"Gupta,-Agrim,-Piotr-Dollar,-and-Ross-Girshick.-&quot;LVIS:-A-dataset-for-large-vocabulary-instance-segmentation.&quot;-Proceedings-of-the-IEEE/CVF-Conference-on-Computer-Vision-and-Pattern-Recognition.-2019.-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Gupta, Agrim, Piotr Dollar, and Ross Girshick. \"LVIS: A dataset for large vocabulary instance segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.</a></span></li><li><span><a href=\"#Kuznetsova,-Alina,-et-al.-&quot;The-open-images-dataset-v4:-Unified-image-classification,-object-detection,-and-visual-relationship-detection-at-scale.&quot;-arXiv-preprint-arXiv:1811.00982-(2018).\" data-toc-modified-id=\"Kuznetsova,-Alina,-et-al.-&quot;The-open-images-dataset-v4:-Unified-image-classification,-object-detection,-and-visual-relationship-detection-at-scale.&quot;-arXiv-preprint-arXiv:1811.00982-(2018).-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Kuznetsova, Alina, et al. \"The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale.\" arXiv preprint arXiv:1811.00982 (2018).</a></span></li><li><span><a href=\"#Shao,-Shuai,-et-al.-&quot;Objects365:-A-large-scale,-high-quality-dataset-for-object-detection.&quot;-Proceedings-of-the-IEEE/CVF-International-Conference-on-Computer-Vision.-2019.\" data-toc-modified-id=\"Shao,-Shuai,-et-al.-&quot;Objects365:-A-large-scale,-high-quality-dataset-for-object-detection.&quot;-Proceedings-of-the-IEEE/CVF-International-Conference-on-Computer-Vision.-2019.-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Shao, Shuai, et al. \"Objects365: A large-scale, high-quality dataset for object detection.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.</a></span></li></ul></li><li><span><a href=\"#Human\" data-toc-modified-id=\"Human-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Human</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hu,-Peiyun,-and-Deva-Ramanan.-&quot;Finding-tiny-faces.&quot;-Proceedings-of-the-IEEE-conference-on-computer-vision-and-pattern-recognition.-2017.\" data-toc-modified-id=\"Hu,-Peiyun,-and-Deva-Ramanan.-&quot;Finding-tiny-faces.&quot;-Proceedings-of-the-IEEE-conference-on-computer-vision-and-pattern-recognition.-2017.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hu, Peiyun, and Deva Ramanan. \"Finding tiny faces.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.</a></span></li><li><span><a href=\"#Shao,-Shuai,-et-al.-&quot;Crowdhuman:-A-benchmark-for-detecting-human-in-a-crowd.&quot;-arXiv-preprint-arXiv:1805.00123-(2018).\" data-toc-modified-id=\"Shao,-Shuai,-et-al.-&quot;Crowdhuman:-A-benchmark-for-detecting-human-in-a-crowd.&quot;-arXiv-preprint-arXiv:1805.00123-(2018).-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Shao, Shuai, et al. \"Crowdhuman: A benchmark for detecting human in a crowd.\" arXiv preprint arXiv:1805.00123 (2018).</a></span></li><li><span><a href=\"#Zhang,-Shifeng,-et-al.-&quot;Widerperson:-A-diverse-dataset-for-dense-pedestrian-detection-in-the-wild.&quot;-IEEE-Transactions-on-Multimedia-22.2-(2019):-380-393.\" data-toc-modified-id=\"Zhang,-Shifeng,-et-al.-&quot;Widerperson:-A-diverse-dataset-for-dense-pedestrian-detection-in-the-wild.&quot;-IEEE-Transactions-on-Multimedia-22.2-(2019):-380-393.-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Zhang, Shifeng, et al. \"Widerperson: A diverse dataset for dense pedestrian detection in the wild.\" IEEE Transactions on Multimedia 22.2 (2019): 380-393.</a></span></li></ul></li><li><span><a href=\"#Mobile-or-vehicle\" data-toc-modified-id=\"Mobile-or-vehicle-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Mobile or vehicle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sivaraman,-Sayanan,-and-Mohan-Manubhai-Trivedi.-&quot;A-general-active-learning-framework-for-on-road-vehicle-recognition-and-tracking.&quot;-IEEE-Transactions-on-Intelligent-Transportation-Systems-11.2-(2010):-267-276.\" data-toc-modified-id=\"Sivaraman,-Sayanan,-and-Mohan-Manubhai-Trivedi.-&quot;A-general-active-learning-framework-for-on-road-vehicle-recognition-and-tracking.&quot;-IEEE-Transactions-on-Intelligent-Transportation-Systems-11.2-(2010):-267-276.-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Sivaraman, Sayanan, and Mohan Manubhai Trivedi. \"A general active-learning framework for on-road vehicle recognition and tracking.\" IEEE Transactions on Intelligent Transportation Systems 11.2 (2010): 267-276.</a></span></li><li><span><a href=\"#Zhang,-Shanshan,-Rodrigo-Benenson,-and-Bernt-Schiele.-&quot;Citypersons:-A-diverse-dataset-for-pedestrian-detection.&quot;-Proceedings-of-the-IEEE-Conference-on-Computer-Vision-and-Pattern-Recognition.-2017.\" data-toc-modified-id=\"Zhang,-Shanshan,-Rodrigo-Benenson,-and-Bernt-Schiele.-&quot;Citypersons:-A-diverse-dataset-for-pedestrian-detection.&quot;-Proceedings-of-the-IEEE-Conference-on-Computer-Vision-and-Pattern-Recognition.-2017.-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Zhang, Shanshan, Rodrigo Benenson, and Bernt Schiele. \"Citypersons: A diverse dataset for pedestrian detection.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.</a></span></li><li><span><a href=\"#Lyu,-Siwei,-et-al.-&quot;UA-DETRAC-2018:-Report-of-AVSS2018-&amp;-IWT4S-challenge-on-advanced-traffic-monitoring.&quot;-2018-15th-IEEE-International-Conference-on-Advanced-Video-and-Signal-Based-Surveillance-(AVSS).-IEEE,-2018.\" data-toc-modified-id=\"Lyu,-Siwei,-et-al.-&quot;UA-DETRAC-2018:-Report-of-AVSS2018-&amp;-IWT4S-challenge-on-advanced-traffic-monitoring.&quot;-2018-15th-IEEE-International-Conference-on-Advanced-Video-and-Signal-Based-Surveillance-(AVSS).-IEEE,-2018.-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Lyu, Siwei, et al. \"UA-DETRAC 2018: Report of AVSS2018 &amp; IWT4S challenge on advanced traffic monitoring.\" 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, 2018.</a></span></li><li><span><a href=\"#Braun,-Markus,-et-al.-&quot;The-eurocity-persons-dataset:-A-novel-benchmark-for-object-detection.&quot;-arXiv-preprint-arXiv:1805.07193-(2018).\" data-toc-modified-id=\"Braun,-Markus,-et-al.-&quot;The-eurocity-persons-dataset:-A-novel-benchmark-for-object-detection.&quot;-arXiv-preprint-arXiv:1805.07193-(2018).-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Braun, Markus, et al. \"The eurocity persons dataset: A novel benchmark for object detection.\" arXiv preprint arXiv:1805.07193 (2018).</a></span></li><li><span><a href=\"#Behrendt,-Karsten,-Libor-Novak,-and-Rami-Botros.-&quot;A-deep-learning-approach-to-traffic-lights:-Detection,-tracking,-and-classification.&quot;-2017-IEEE-International-Conference-on-Robotics-and-Automation-(ICRA).-IEEE,-2017.\" data-toc-modified-id=\"Behrendt,-Karsten,-Libor-Novak,-and-Rami-Botros.-&quot;A-deep-learning-approach-to-traffic-lights:-Detection,-tracking,-and-classification.&quot;-2017-IEEE-International-Conference-on-Robotics-and-Automation-(ICRA).-IEEE,-2017.-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Behrendt, Karsten, Libor Novak, and Rami Botros. \"A deep learning approach to traffic lights: Detection, tracking, and classification.\" 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2017.</a></span></li></ul></li><li><span><a href=\"#Aerial\" data-toc-modified-id=\"Aerial-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Aerial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Xia,-Gui-Song,-et-al.-&quot;DOTA:-A-large-scale-dataset-for-object-detection-in-aerial-images.&quot;-Proceedings-of-the-IEEE-conference-on-computer-vision-and-pattern-recognition.-2018.\" data-toc-modified-id=\"Xia,-Gui-Song,-et-al.-&quot;DOTA:-A-large-scale-dataset-for-object-detection-in-aerial-images.&quot;-Proceedings-of-the-IEEE-conference-on-computer-vision-and-pattern-recognition.-2018.-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Xia, Gui-Song, et al. \"DOTA: A large-scale dataset for object detection in aerial images.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.</a></span></li><li><span><a href=\"#Du,-Dawei,-et-al.-&quot;The-unmanned-aerial-vehicle-benchmark:-Object-detection-and-tracking.&quot;-Proceedings-of-the-European-Conference-on-Computer-Vision-(ECCV).-2018.\" data-toc-modified-id=\"Du,-Dawei,-et-al.-&quot;The-unmanned-aerial-vehicle-benchmark:-Object-detection-and-tracking.&quot;-Proceedings-of-the-European-Conference-on-Computer-Vision-(ECCV).-2018.-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Du, Dawei, et al. \"The unmanned aerial vehicle benchmark: Object detection and tracking.\" Proceedings of the European Conference on Computer Vision (ECCV). 2018.</a></span></li><li><span><a href=\"#Wang,-Jinwang,-et-al.-&quot;Tiny-Object-Detection-in-Aerial-Images.&quot;-2020-25th-International-Conference-on-Pattern-Recognition-(ICPR).-IEEE,-2021.\" data-toc-modified-id=\"Wang,-Jinwang,-et-al.-&quot;Tiny-Object-Detection-in-Aerial-Images.&quot;-2020-25th-International-Conference-on-Pattern-Recognition-(ICPR).-IEEE,-2021.-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Wang, Jinwang, et al. \"Tiny Object Detection in Aerial Images.\" 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021.</a></span></li></ul></li><li><span><a href=\"#ETC\" data-toc-modified-id=\"ETC-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>ETC</a></span><ul class=\"toc-item\"><li><span><a href=\"#Goldman,-Eran,-et-al.-&quot;Precise-detection-in-densely-packed-scenes.&quot;-Proceedings-of-the-IEEE/CVF-Conference-on-Computer-Vision-and-Pattern-Recognition.-2019.\" data-toc-modified-id=\"Goldman,-Eran,-et-al.-&quot;Precise-detection-in-densely-packed-scenes.&quot;-Proceedings-of-the-IEEE/CVF-Conference-on-Computer-Vision-and-Pattern-Recognition.-2019.-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Goldman, Eran, et al. \"Precise detection in densely packed scenes.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.</a></span></li></ul></li><li><span><a href=\"#Ref\" data-toc-modified-id=\"Ref-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Ref</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932cee03",
   "metadata": {},
   "source": [
    "## General\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc4c5d",
   "metadata": {},
   "source": [
    "### Everingham, Mark, et al. \"The pascal visual object classes (voc) challenge.\" International journal of computer vision 88.2 (2010): 303-338.\n",
    "\n",
    "The PASCAL Visual Object Classes (VOC) 2012 dataset contains 20 object categories including vehicles, household, animals, and other: aeroplane, bicycle, boat, bus, car, motorbike, train, bottle, chair, dining table, potted plant, sofa, TV/monitor, bird, cat, cow, dog, horse, sheep, and person. Each image in this dataset has pixel-level segmentation annotations, bounding box annotations, and object class annotations. This dataset has been widely used as a benchmark for object detection, semantic segmentation, and classification tasks. The PASCAL VOC dataset is split into three subsets: 1,464 images for training, 1,449 images for validation and a private testing set.\n",
    "\n",
    "![](https://kjhov195.github.io/post_img/200209/image11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3eba8",
   "metadata": {},
   "source": [
    "### Lin, Tsung-Yi, et al. \"Microsoft coco: Common objects in context.\" European conference on computer vision. Springer, Cham, 2014.\n",
    "\n",
    "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model\n",
    "\n",
    "![](https://cocodataset.org/images/coco-examples.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de9e68",
   "metadata": {},
   "source": [
    "### Gupta, Agrim, Piotr Dollar, and Ross Girshick. \"LVIS: A dataset for large vocabulary instance segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "\n",
    "Progress on object detection is enabled by datasets that focus the research community's attention on open challenges. This process led us from simple images to complex scenes and from bounding boxes to segmentation masks. In this work, we introduce LVIS (pronounced `el-vis'): a new dataset for Large Vocabulary Instance Segmentation. We plan to collect ~2 million high-quality instance segmentation masks for over 1000 entry-level object categories in 164k images. Due to the Zipfian distribution of categories in natural images, LVIS naturally has a long tail of categories with few training samples. Given that state-of-the-art deep learning methods for object detection perform poorly in the low-sample regime, we believe that our dataset poses an important and exciting new scientific challenge. LVIS is available at http://www.lvisdataset.org.\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/lvis.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3b122",
   "metadata": {},
   "source": [
    "### Kuznetsova, Alina, et al. \"The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale.\" arXiv preprint arXiv:1811.00982 (2018).\n",
    "\n",
    "We present Open Images V4, a dataset of 9.2M images with unified annotations for image classification, object detection and visual relationship detection. The images have a Creative Commons Attribution license that allows to share and adapt the material, and they have been collected from Flickr without a predefined list of class names or tags, leading to natural class statistics and avoiding an initial design bias. Open Images V4 offers large scale across several dimensions: 30.1M image-level labels for 19.8k concepts, 15.4M bounding boxes for 600 object classes, and 375k visual relationship annotations involving 57 classes. For object detection in particular, we provide 15x more bounding boxes than the next largest datasets (15.4M boxes on 1.9M images). The images often show complex scenes with several objects (8 annotated objects per image on average). We annotated visual relationships between them, which support visual relationship detection, an emerging task that requires structured reasoning. We provide in-depth comprehensive statistics about the dataset, we validate the quality of the annotations, we study how the performance of several modern models evolves with increasing amounts of training data, and we demonstrate two applications made possible by having unified annotations of multiple types coexisting in the same images. We hope that the scale, quality, and variety of Open Images V4 will foster further research and innovation even beyond the areas of image classification, object detection, and visual relationship detection.\n",
    "\n",
    "![](https://miro.medium.com/max/800/1*0YYlvu7h-WSgYyiRa5idSQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac7500",
   "metadata": {},
   "source": [
    "### Shao, Shuai, et al. \"Objects365: A large-scale, high-quality dataset for object detection.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.\n",
    "\n",
    "Objects365 is a large-scale object detection dataset, Objects365, which has 365 object categories over 600K training images. More than 10 million, high-quality bounding boxes are manually labeled through a three-step, carefully designed annotation pipeline. It is the largest object detection dataset (with full annotation) so far and establishes a more challenging benchmark for the community.\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/Screenshot_2021-02-02_at_09.36.55.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21f949",
   "metadata": {},
   "source": [
    "## Human\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c6a75",
   "metadata": {},
   "source": [
    "### Hu, Peiyun, and Deva Ramanan. \"Finding tiny faces.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.\n",
    "\n",
    "Though tremendous strides have been made in object recognition, one of the remaining open challenges is detecting small objects. We explore three aspects of the problem in the context of finding small faces: the role of scale invariance, image resolution, and contextual reasoning. While most recognition approaches aim to be scale-invariant, the cues for recognizing a 3px tall face are fundamentally different than those for recognizing a 300px tall face. We take a different approach and train separate detectors for different scales. To maintain efficiency, detectors are trained in a multi-task fashion: they make use of features extracted from multiple layers of single (deep) feature hierarchy. While training detectors for large objects is straightforward, the crucial challenge remains training detectors for small objects. We show that context is crucial, and define templates that make use of massively-large receptive fields (where 99% of the template extends beyond the object of interest). Finally, we explore the role of scale in pre-trained deep networks, providing ways to extrapolate networks tuned for limited scales to rather extreme ranges. We demonstrate state-of-the-art results on massively-benchmarked face datasets (FDDB and WIDER FACE). In particular, when compared to prior art on WIDER FACE, our results reduce error by a factor of 2 (our models produce an AP of 82% while prior art ranges from 29-64%). \n",
    "\n",
    "![](https://raw.githubusercontent.com/peiyunh/tiny/master/selfie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb5522",
   "metadata": {},
   "source": [
    "### Shao, Shuai, et al. \"Crowdhuman: A benchmark for detecting human in a crowd.\" arXiv preprint arXiv:1805.00123 (2018).\n",
    "\n",
    "CrowdHuman is a large and rich-annotated human detection dataset, which contains 15,000, 4,370 and 5,000 images collected from the Internet for training, validation and testing respectively. The number is more than 10× boosted compared with previous challenging pedestrian detection dataset like CityPersons. The total number of persons is also noticeably larger than the others with ∼340k person and ∼99k ignore region annotations in the CrowdHuman training subset.\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/CrowdHuman-0000003420-7651fd76.jpg)\n",
    "\n",
    "- Chu, Xuangeng, et al. \"Detection in crowded scenes: One proposal, multiple predictions.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593e7bc",
   "metadata": {},
   "source": [
    "### Zhang, Shifeng, et al. \"Widerperson: A diverse dataset for dense pedestrian detection in the wild.\" IEEE Transactions on Multimedia 22.2 (2019): 380-393.\n",
    "\n",
    "WiderPerson contains a total of 13,382 images with 399,786 annotations, i.e., 29.87 annotations per image, which means this dataset contains dense pedestrians with various kinds of occlusions. Hence, pedestrians in the proposed dataset are extremely challenging due to large variations in the scenario and occlusion, which is suitable to evaluate pedestrian detectors in the wild.\n",
    "\n",
    "![](http://www.cbsr.ia.ac.cn/users/sfzhang/WiderPerson/files/intro.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db6388",
   "metadata": {},
   "source": [
    "## Mobile or vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54628afe",
   "metadata": {},
   "source": [
    "### Sivaraman, Sayanan, and Mohan Manubhai Trivedi. \"A general active-learning framework for on-road vehicle recognition and tracking.\" IEEE Transactions on Intelligent Transportation Systems 11.2 (2010): 267-276.\n",
    "\n",
    "This is a dataset for vehicle detection. It consists of:  \n",
    "\n",
    "- Three color video sequences captured at different times of the day and illumination settings: morning, evening, sunny, cloudy, etc.\n",
    "- Different driving environments: highway and urban.\n",
    "- Varying traffic conditions: light to dense traffic\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/alvert.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d7710",
   "metadata": {},
   "source": [
    "### Zhang, Shanshan, Rodrigo Benenson, and Bernt Schiele. \"Citypersons: A diverse dataset for pedestrian detection.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n",
    "\n",
    "The CityPersons dataset is a subset of Cityscapes which only consists of person annotations. There are 2975 images for training, 500 and 1575 images for validation and testing. The average of the number of pedestrians in an image is 7. The visible-region and full-body annotations are provided.\n",
    "\n",
    "\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/CityPersons-0000000865-555caf6c_SYqFKMQ.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4524d",
   "metadata": {},
   "source": [
    "### Lyu, Siwei, et al. \"UA-DETRAC 2018: Report of AVSS2018 & IWT4S challenge on advanced traffic monitoring.\" 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, 2018.\n",
    "\n",
    "Consists of 100 challenging video sequences captured from real-world traffic scenes (over 140,000 frames with rich annotations, including occlusion, weather, vehicle category, truncation, and vehicle bounding boxes) for object detection, object tracking and MOT system.\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/det.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5739dd5",
   "metadata": {},
   "source": [
    "### Braun, Markus, et al. \"The eurocity persons dataset: A novel benchmark for object detection.\" arXiv preprint arXiv:1805.07193 (2018).\n",
    "\n",
    "The EuroCity Persons dataset provides a large number of highly diverse, accurate and detailed annotations of pedestrians, cyclists and other riders in urban traffic scenes. The images for this dataset were collected on-board a moving vehicle in 31 cities of 12 European countries. With over 238,200 person instances manually labeled in over 47,300 images, EuroCity Persons is nearly one order of magnitude larger than person datasets used previously for benchmarking. The dataset furthermore contains a large number of person orientation annotations (over 211,200).\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/Screenshot_2021-01-28_at_14.39.48.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfbc6e",
   "metadata": {},
   "source": [
    "### Behrendt, Karsten, Libor Novak, and Rami Botros. \"A deep learning approach to traffic lights: Detection, tracking, and classification.\" 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2017.\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/bslt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb0885",
   "metadata": {},
   "source": [
    "## Aerial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc1e26",
   "metadata": {},
   "source": [
    "### Xia, Gui-Song, et al. \"DOTA: A large-scale dataset for object detection in aerial images.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.\n",
    "\n",
    "DOTA is a large-scale dataset for object detection in aerial images. It can be used to develop and evaluate object detectors in aerial images. The images are collected from different sensors and platforms. Each image is of the size in the range from 800 × 800 to 20,000 × 20,000 pixels and contains objects exhibiting a wide variety of scales, orientations, and shapes. The instances in DOTA images are annotated by experts in aerial image interpretation by arbitrary (8 d.o.f.) quadrilateral. We will continue to update DOTA, to grow in size and scope to reflect evolving real-world conditions. Now it has three versions:\n",
    "\n",
    "- DOTA-v1.0 contains 15 common categories, 2,806 images and 188, 282 instances. The proportions of the training set, validation set, and testing set in DOTA-v1.0 are 1/2, 1/6, and 1/3, respectively.\n",
    "\n",
    "- DOTA-v1.5 uses the same images as DOTA-v1.0, but the extremely small instances (less than 10 pixels) are also annotated. Moreover, a new category, ”container crane” is added. It contains 403,318 instances in total. The number of images and dataset splits are the same as DOTA-v1.0. This version was released for the DOAI Challenge 2019 on Object Detection in Aerial Images in conjunction with IEEE CVPR 2019.\n",
    "\n",
    "- DOTA-v2.0 collects more Google Earth, GF-2 Satellite, and aerial images. There are 18 common categories, 11,268 images and 1,793,658 instances in DOTA-v2.0. Compared to DOTA-v1.5, it further adds the new categories of ”airport” and ”helipad”. The 11,268 images of DOTA are split into training, validation, test-dev, and test-challenge sets. To avoid the problem of overfitting, the proportion of training and validation set is smaller than the test set. Furthermore, we have two test sets, namely test-dev and test-challenge. Training contains 1,830 images and 268,627 instances. Validation contains 593 images and 81,048 instances. We released the images and ground truths for training and validation sets. Test-dev contains 2,792 images and 353,346 instances. We released the images but not the ground truths. Test-challenge contains 6,053 images and 1,090,637 instances.\n",
    "\n",
    "![](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4782438",
   "metadata": {},
   "source": [
    "### Du, Dawei, et al. \"The unmanned aerial vehicle benchmark: Object detection and tracking.\" Proceedings of the European Conference on Computer Vision (ECCV). 2018.\n",
    "\n",
    "UAVDT is a large scale challenging UAV Detection and Tracking benchmark (i.e., about 80, 000 representative frames from 10 hours raw videos) for 3 important fundamental tasks, i.e., object DETection (DET), Single Object Tracking (SOT) and Multiple Object Tracking (MOT).\n",
    "\n",
    "The dataset is captured by UAVs in various complex scenarios. The objects of interest in this benchmark are vehicles. The frames are manually annotated with bounding boxes and some useful attributes, e.g., vehicle category and occlusion.\n",
    "\n",
    "The UAVDT benchmark consists of 100 video sequences, which are selected from over 10 hours of videos taken with an UAV platform at a number of locations in urban areas, representing various common scenes including squares, arterial streets, toll stations, highways, crossings and T-junctions. The videos are recorded at 30 frames per seconds (fps), with the JPEG image resolution of 1080 × 540 pixels.\n",
    "\n",
    "![](https://paperswithcode.com/media/datasets/uavdt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7f653",
   "metadata": {},
   "source": [
    "### Wang, Jinwang, et al. \"Tiny Object Detection in Aerial Images.\" 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021.\n",
    "\n",
    "![](https://paperswithcode.com/media/thumbnails/task/task-0000000509-66402dc1_C47uozM.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48060d23",
   "metadata": {},
   "source": [
    "## ETC\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3d821",
   "metadata": {},
   "source": [
    "### Goldman, Eran, et al. \"Precise detection in densely packed scenes.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "\n",
    "The Sku110k dataset provides 11,762 images with more than 1.7 million annotated bounding boxes captured in densely packed scenarios, including 8,233 images for training, 588 images for validation, and 2,941 images for testing. There are around 1,733,678 instances in total. The images are collected from thousands of supermarket stores and are of various scales, viewing angles, lighting conditions, and noise levels. All the images are resized into a resolution of one megapixel. Most of the instances in the dataset are tightly packed and typically of a certain orientation in the rage of [−15∘, 15∘].\n",
    "\n",
    "![](https://github.com/eg4000/SKU110K_CVPR19/raw/master/figures/teaser_width.jpg)\n",
    "\n",
    "- https://github.com/eg4000/SKU110K_CVPR19\n",
    "- https://towardsdatascience.com/deep-learning-based-object-detection-in-crowded-scenes-1c9fddbd7bc4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f42ce3",
   "metadata": {},
   "source": [
    "## Ref\n",
    "- https://github.com/knhngchn/awesome-tiny-object-detection#datasets\n",
    "- https://github.com/hoya012/deep_learning_object_detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
